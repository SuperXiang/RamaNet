{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "search.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZP0hXWaT4cO"
      },
      "source": [
        "SETUP ENVIRONMENT:\n",
        "\n",
        "Install Conda\n",
        "\n",
        "Install PyRosetta (the protein folding library)\n",
        "\n",
        "Install sherpa (the population search library)\n",
        "\n",
        "Install Biopython (library to analyse the protein structure)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBmlusZpTHHA"
      },
      "source": [
        "!wget https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda install --channel defaults conda python=3.6 --yes\n",
        "!conda update --channel defaults --all --yes\n",
        "import sys\n",
        "_ = (sys.path.append(\"/usr/local/lib/python3.6/site-packages\"))\n",
        "!pip3 install biopython parameter-sherpa\n",
        "!conda install --channel https://levinthal:paradox@conda.graylab.jhu.edu pyrosetta --yes\n",
        "!apt install dssp\n",
        "!rm -r sample_data/\n",
        "!rm Miniconda3-4.5.4-Linux-x86_64.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9FnbePkTqBv"
      },
      "source": [
        "Download the dataset in serialised form. The dataset has already been normalised"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZsfX-VoRtYv"
      },
      "source": [
        "!wget https://www.dropbox.com/s/1ne938re177ld6o/PS%2BCM.hdf5.xz?dl=0\n",
        "!mv PS+CM.hdf5.xz?dl=0 PS+CM.hdf5.xz\n",
        "!xz -d PS+CM.hdf5.xz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYV_gPHSUVK2"
      },
      "source": [
        "Import statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cf8abc9SZ1B"
      },
      "source": [
        "import os\n",
        "import h5py\n",
        "import math\n",
        "import keras\n",
        "import sherpa\n",
        "import Bio.PDB\n",
        "import numpy as np\n",
        "from pyrosetta import *\n",
        "from pyrosetta.toolbox import *\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential, Model\n",
        "from keras.losses import BinaryCrossentropy\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers import Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers import Input, Dense, Reshape, Flatten\n",
        "from keras.layers import UpSampling2D, BatchNormalization\n",
        "from keras.layers import Dropout, GlobalMaxPooling2D, Conv2DTranspose\n",
        "init('-out:level 0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfwajRZNYOuE"
      },
      "source": [
        "Import dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOQloetnYPB-",
        "outputId": "a82872db-9925-4256-d273-57e92631650d"
      },
      "source": [
        "with h5py.File('PS+CM.hdf5', 'r') as data: dataset=data['default'][()]\n",
        "dataset = np.reshape(dataset, (-1, 150, 152, 1))\n",
        "shape = dataset.shape[1:]\n",
        "print(dataset.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30442, 150, 152, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiqlIt4WUXjq"
      },
      "source": [
        "Call the folding function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt90c80ePkjl"
      },
      "source": [
        "def fold(P, S, C):\n",
        "\tP = np.ndarray.tolist(P)\n",
        "\tS = np.ndarray.tolist(S)\n",
        "\tsize = int(len(P))\n",
        "\tVs = []\n",
        "\tfor numb in range(size): Vs.append('A')\n",
        "\tsequence = ''.join(Vs)\n",
        "\tpose = pose_from_sequence(sequence)\n",
        "\tfor count, (phi, psi) in enumerate(zip(P, S)):\n",
        "\t\tpose.set_phi(count+1, float(phi))\n",
        "\t\tpose.set_psi(count+1, float(psi))\n",
        "\tpose.dump_pdb('angles.pdb')\n",
        "\tstructure = Bio.PDB.PDBParser().get_structure('angles', 'angles.pdb')\n",
        "\tdssp = Bio.PDB.DSSP(structure[0], 'angles.pdb', acc_array='Wilke')\n",
        "\tppb = Bio.PDB.Polypeptide.PPBuilder()\n",
        "\tchain = ppb.build_peptides(structure, aa_only=False)[0]\n",
        "\tSS = []\n",
        "\tfor aa in dssp:\n",
        "\t\tif aa[2] == 'G' or aa[2] == 'H' or aa[2] == 'I': SSname = 'H'\n",
        "\t\telif aa[2] == 'B' or aa[2] == 'E': SSname = 'S'\n",
        "\t\telse: SSname = 'L'\n",
        "\t\tSS.append(SSname)\n",
        "\ttry:\n",
        "\t\tfor i in enumerate(reversed(SS)):\n",
        "\t\t\tif i[1] != 'L':\n",
        "\t\t\t\tnum = i[0]\n",
        "\t\t\t\tbreak\n",
        "\t\tfor model in structure:\n",
        "\t\t\tfor chain in model:\n",
        "\t\t\t\tfor i in reversed(range(150-num+1, 150+1)):\n",
        "\t\t\t\t\tchain.detach_child((' ', i, ' '))\n",
        "\t\tio = Bio.PDB.PDBIO()\n",
        "\t\tio.set_structure(structure)\n",
        "\t\tio.save('turnicated.pdb')\n",
        "\t\tos.remove('angles.pdb')\n",
        "\t\tpose = pose_from_pdb('turnicated.pdb')\n",
        "\texcept:\n",
        "\t\tos.remove('angles.pdb')\n",
        "\t\traise ValueError('No Secondary Structures')\n",
        "\tsize = pose.residues.__len__()\n",
        "\twith open('constraints.cst', 'w') as thefile:\n",
        "\t\tfor a in range(1, size+1):\n",
        "\t\t\tfor A in range(1, size+1):\n",
        "\t\t\t\tline = 'AtomPair CA {} CA {} GAUSSIANFUNC {} 1.0\\n'\\\n",
        "\t\t\t\t.format(a, A, C[a][A])\n",
        "\t\t\t\tthefile.write(line)\n",
        "\tcon = pyrosetta.rosetta.protocols.constraint_movers.ConstraintSetMover()\n",
        "\tcon.constraint_file('constraints.cst')\n",
        "\tcon.add_constraints(True)\n",
        "\tcon.apply(pose)\n",
        "\tscorefxn = get_fa_scorefxn()\n",
        "\tscore_manager = pyrosetta.rosetta.core.scoring.ScoreTypeManager()\n",
        "\tconstraint = score_manager.score_type_from_name('atom_pair_constraint')\n",
        "\tscorefxn.set_weight(constraint, 5)\n",
        "\trelax = pyrosetta.rosetta.protocols.relax.FastRelax()\n",
        "\trelax.set_scorefxn(scorefxn)\n",
        "\tos.remove('turnicated.pdb')\n",
        "\tos.remove('constraints.cst')\n",
        "\trelax.apply(pose)\n",
        "\tpose.dump_pdb('backbone.pdb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v26p8MgUZwN"
      },
      "source": [
        "Call the protein Structure Quality Metric function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWE3ZY6OTiQ8"
      },
      "source": [
        "import os\n",
        "import math\n",
        "import Bio.PDB\n",
        "import numpy as np\n",
        "\n",
        "def SQM(filename):\n",
        "\tparser = Bio.PDB.PDBParser()\n",
        "\tstructure = parser.get_structure('{}'.format(filename), filename)\n",
        "\tdssp = Bio.PDB.DSSP(structure[0], filename, acc_array='Wilke')\n",
        "\tAminoAcid = {\t'A':129, 'P':159, 'N':195, 'H':224,\n",
        "\t\t\t\t\t'V':174, 'Y':263, 'C':167, 'K':236,\n",
        "\t\t\t\t\t'I':197, 'F':240, 'Q':225, 'S':155,\n",
        "\t\t\t\t\t'L':201, 'W':285, 'E':223, 'T':172,\n",
        "\t\t\t\t\t'M':224, 'R':274, 'G':104, 'D':193}\n",
        "\tsec_struct = []\n",
        "\tSASA = []\n",
        "\tfor aa in dssp:\n",
        "\t\tif   aa[2] == 'G' or aa[2] == 'H' or aa[2] == 'I': ss = 'H'\n",
        "\t\telif aa[2] == 'B' or aa[2] == 'E':                 ss = 'S'\n",
        "\t\telif aa[2] == 'S' or aa[2] == 'T' or aa[2] == '-': ss = 'L'\n",
        "\t\tsec_struct.append(ss)\n",
        "\t\tsasa = AminoAcid[aa[1]]*aa[3]\n",
        "\t\tif sasa <= 25:      sasa = 'C'\n",
        "\t\telif 25 < sasa < 40:sasa = 'B'\n",
        "\t\telif sasa >= 40:    sasa = 'S'\n",
        "\t\tSASA.append(sasa)\n",
        "\t''' Secondary structure measurement '''\n",
        "\tH = len([x for x in sec_struct if x == 'H'])\n",
        "\tS = len([x for x in sec_struct if x == 'S'])\n",
        "\tL = len([x for x in sec_struct if x == 'L'])\n",
        "\ttotal = len(sec_struct)\n",
        "\tratio = (H+S)/total\n",
        "\tlimit = 1\n",
        "\tslope = 10\n",
        "\tbias  = 0.5\n",
        "\tSS = limit/(1+np.exp(slope*(bias-ratio)))\n",
        "\t''' SASA measurement '''\n",
        "\tsurface = len([x for x in SASA if x == 'S'])\n",
        "\tboundery = len([x for x in SASA if x == 'B'])\n",
        "\tin_core = len([x for x in SASA if x == 'C'])\n",
        "\ttotal = len(SASA)\n",
        "\tpercent = (in_core*100)/total\n",
        "\tCore = (2.50662/math.sqrt(2*(math.pi)))*math.exp(-((percent-30)**2)/100)\n",
        "\t''' Radius of gyration measurement '''\n",
        "\tcoord = list()\n",
        "\tmass = list()\n",
        "\tStructure = open(filename, 'r')\n",
        "\tfor line in Structure:\n",
        "\t\ttry:\n",
        "\t\t    line = line.split()\n",
        "\t\t    x = float(line[6])\n",
        "\t\t    y = float(line[7])\n",
        "\t\t    z = float(line[8])\n",
        "\t\t    coord.append([x, y, z])\n",
        "\t\t    if   line[-1] == 'C': mass.append(12.0107)\n",
        "\t\t    elif line[-1] == 'O': mass.append(15.9994)\n",
        "\t\t    elif line[-1] == 'N': mass.append(14.0067)\n",
        "\t\t    elif line[-1] == 'S': mass.append(32.065)\n",
        "\t\texcept: pass\n",
        "\txm = [(m*i, m*j, m*k) for (i, j, k), m in zip(coord, mass)]\n",
        "\ttmass = sum(mass)\n",
        "\trr = sum(mi*i + mj*j + mk*k for (i, j, k), (mi, mj, mk) in zip(coord, xm))\n",
        "\tmm = sum((sum(i)/tmass)**2 for i in zip(*xm))\n",
        "\trg = math.sqrt(rr/tmass-mm)\n",
        "\tRg = (2.50662/math.sqrt(2*(math.pi)))*math.exp(-((rg-12)**2)/40)\n",
        "\t''' The metric '''\n",
        "\tTheMetric = sum([SS, Core, Rg])/3\n",
        "\tif TheMetric <= 0.8: choice = False\n",
        "\telse: choice = True\n",
        "\treturn(round(TheMetric, 5), choice)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGJm2cT_UiIT"
      },
      "source": [
        "Call the GAN neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOnWgqa6Tjy1"
      },
      "source": [
        "def TheModel(lrG   = 0.001,\n",
        "\t\t\tlrD    = 0.001,\n",
        "\t\t\tnodeG  = 2,\n",
        "\t\t\tnodeD  = 2,\n",
        "\t\t\tmoment = 0.99,\n",
        "\t\t\talpha  = 0.2,\n",
        "\t\t\tdrop   = 0.2,\n",
        "\t\t\tkernel = 2,\n",
        "\t\t\tstride = 2,\n",
        "\t\t\tlatent = 100,\n",
        "\t\t\tbatchs = 32,\n",
        "\t\t\tepochs = 10,\n",
        "\t\t\tC_MAX  = 12):\n",
        "\tG = Sequential()\n",
        "\tG.add(Dense(2**(nodeG+1) * 75 * 38, activation='relu',input_dim=latent))\n",
        "\tG.add(Reshape((75, 38, 2**(nodeG+1))))\n",
        "\tG.add(UpSampling2D(size=(1, 2)))\n",
        "\tG.add(Conv2D(2**(nodeG+1), kernel_size=(kernel, kernel), padding='same'))\n",
        "\tG.add(BatchNormalization(momentum=moment))\n",
        "\tG.add(Activation('relu'))\n",
        "\tG.add(UpSampling2D())\n",
        "\tG.add(Conv2D(2**(nodeG+0), kernel_size=(kernel, kernel), padding='same'))\n",
        "\tG.add(BatchNormalization(momentum=moment))\n",
        "\tG.add(Activation('relu'))\n",
        "\tG.add(Conv2D(1, kernel_size=(kernel, kernel), padding='same'))\n",
        "\tG.add(Activation('tanh'))\n",
        "\tD = Sequential()\n",
        "\tD.add(Conv2D(2**(nodeD+0), kernel_size=(kernel, kernel), strides=(stride, stride), input_shape=shape, padding='same'))\n",
        "\tD.add(LeakyReLU(alpha=alpha))\n",
        "\tD.add(Dropout(drop))\n",
        "\tD.add(Conv2D(2**(nodeD+1), kernel_size=(kernel, kernel), strides=(stride, stride), padding='same'))\n",
        "\tD.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
        "\tD.add(BatchNormalization(momentum=moment))\n",
        "\tD.add(LeakyReLU(alpha=alpha))\n",
        "\tD.add(Dropout(drop))\n",
        "\tD.add(Conv2D(2**(nodeD+2), kernel_size=(kernel, kernel), strides=(stride, stride), padding='same'))\n",
        "\tD.add(BatchNormalization(momentum=moment))\n",
        "\tD.add(LeakyReLU(alpha=alpha))\n",
        "\tD.add(Dropout(drop))\n",
        "\tD.add(Conv2D(2**(nodeD+3), kernel_size=(kernel, kernel), strides=(stride-1, stride-1), padding='same'))\n",
        "\tD.add(BatchNormalization(momentum=moment))\n",
        "\tD.add(LeakyReLU(alpha=alpha))\n",
        "\tD.add(Dropout(drop))\n",
        "\tD.add(Flatten())\n",
        "\tD.add(Dense(1, activation='sigmoid'))\n",
        "\tD.compile(optimizer=keras.optimizers.Adam(lrD), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\tz = keras.layers.Input(shape=(latent,))\n",
        "\tgen = G(z)\n",
        "\tD.trainable = False\n",
        "\tvalidity = D(gen)\n",
        "\tAM = keras.models.Model(z, validity)\n",
        "\tAM.compile(optimizer=keras.optimizers.Adam(lrG), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\tEpc = []\n",
        "\tDTy = []\n",
        "\tDFy = []\n",
        "\tGNy = []\n",
        "\ty_true = np.ones([batchs, 1])\n",
        "\ty_false = np.zeros([batchs, 1])\n",
        "\tk = 3\n",
        "\tfor epoch in range(1, epochs+1):\n",
        "\t\tX_real = dataset[np.random.randint(0,\n",
        "\t\tdataset.shape[0],\n",
        "\t\tsize=batchs)]\n",
        "\t\tX_noise = np.random.normal(0.0, 1.0, size=[batchs, latent])\n",
        "\t\tX_fake = G.predict(X_noise)\n",
        "\t\tdT_loss = D.train_on_batch(X_real, y_true)\n",
        "\t\tdF_loss = D.train_on_batch(X_fake, y_false)\n",
        "\t\tDT_loss = round(float(dT_loss[0]), 3)\n",
        "\t\tDF_loss = round(float(dF_loss[0]), 3)\n",
        "\t\ttry: g_loss = [GNy[-1]]\n",
        "\t\texcept: g_loss = [0]\n",
        "\t\tif epoch % (k+1) == 0: g_loss = AM.train_on_batch(X_noise, y_true)\n",
        "\t\tGN_loss = round(float(g_loss[0]), 3)\n",
        "\tmetric = []\n",
        "\tfor i in range(1, 1+1):\n",
        "\t\tnoise = np.random.normal(0.0, 1.0, size=[1, latent])\n",
        "\t\tgen = G.predict(noise)\n",
        "\t\tP = gen[:,:,0]\n",
        "\t\tS = gen[:,:,1]\n",
        "\t\tC = gen[:,:,2:]\n",
        "\t\tP += 1\n",
        "\t\tS += 1\n",
        "\t\tC += 1\n",
        "\t\tP *= 180\n",
        "\t\tS *= 180\n",
        "\t\tC *= (C_MAX/2)\n",
        "\t\tP = np.reshape(P, (150,))\n",
        "\t\tS = np.reshape(S, (150,))\n",
        "\t\tC = np.reshape(C, (150, 150))\n",
        "\t\ttry:\n",
        "\t\t\tfold(P, S, C)\n",
        "\t\t\tmetric.append(SQM('backbone.pdb')[0])\n",
        "\t\t\tos.remove('backbone.pdb')\n",
        "\t\texcept:\n",
        "\t\t\tmetric.append(0)\n",
        "\treturn(sum(metric)/len(metric))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqNPSWkYUmVO"
      },
      "source": [
        "Setup the search paramenters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaBAJIeeTMxw"
      },
      "source": [
        "parameters = [\n",
        "\tsherpa.Continuous('lrG',    [5e-3, 4e-3], 'log'),#[1e-2, 1e-5], 'log'),\n",
        "\tsherpa.Continuous('lrD',    [1e-3, 2e-3], 'log'),#[1e-2, 1e-5], 'log'),\n",
        "\tsherpa.Discrete(  'nodeG',  [3, 4]),#[4, 8]),\n",
        "\tsherpa.Discrete(  'nodeD',  [3, 4]),#[4, 5]),\n",
        "    sherpa.Continuous('moment', [0.5, 0.6]),#[0.6, 0.99]),\n",
        "\tsherpa.Continuous('alpha',  [0.2, 0.3]),#[0.1, 0.5]),\n",
        "\tsherpa.Continuous('drop',   [0.3, 0.4]),#[0.0, 0.5]),\n",
        "\tsherpa.Choice(    'kernel', [2, 3]),#[2, 3, 5]),\n",
        "\tsherpa.Choice(    'stride', [2]),#[2]),\n",
        "\tsherpa.Ordinal(   'latent', [128, 512]),#[128, 512]),\n",
        "\tsherpa.Ordinal(   'batchs', [32, 256]),#[32, 512]),\n",
        "\tsherpa.Choice(    'epochs', [7000])]#[1000, 3000, 5000, 7000, 9000, 10000])]\n",
        "\n",
        "algorithm = sherpa.algorithms.PopulationBasedTraining(\n",
        "\tpopulation_size=2,\n",
        "\tnum_generations=5)\n",
        "\n",
        "study = sherpa.Study(\n",
        "\tparameters=parameters,\n",
        "\talgorithm=algorithm,\n",
        "\tlower_is_better=False,\n",
        "\tdisable_dashboard=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEdeTknaXxQQ"
      },
      "source": [
        "Start the search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfKIPNwVXv6_",
        "outputId": "775f414e-09d9-4a90-84bc-b16dcee2e1d4"
      },
      "source": [
        "for trial in study:\n",
        "\tkeras.backend.clear_session()\n",
        "\tgeneration = trial.parameters['generation']\n",
        "\tload_from  = trial.parameters['load_from']\n",
        "\tprint('-'*55)\n",
        "\tprint('Generation {} - Population {}'\\\n",
        "\t.format(generation, trial.parameters['save_to']))\n",
        "\tmetric = TheModel(\tlrG    = trial.parameters['lrG'],\n",
        "\t\t\t\t\t\tlrD    = trial.parameters['lrD'],\n",
        "\t\t\t\t\t\tnodeG  = trial.parameters['nodeG'],\n",
        "\t\t\t\t\t\tnodeD  = trial.parameters['nodeD'],\n",
        "\t\t\t\t\t\t#moment = trial.parameters['moment'],\n",
        "\t\t\t\t\t\talpha  = trial.parameters['alpha'],\n",
        "\t\t\t\t\t\tdrop   = trial.parameters['drop'],\n",
        "\t\t\t\t\t\tkernel = trial.parameters['kernel'],\n",
        "\t\t\t\t\t\tstride = trial.parameters['stride'],\n",
        "\t\t\t\t\t\tlatent = trial.parameters['latent'],\n",
        "\t\t\t\t\t\tbatchs = trial.parameters['batchs'],\n",
        "\t\t\t\t\t\tepochs = trial.parameters['epochs'])\n",
        "\tprint('Average Metric: {}'.format(metric))\n",
        "\tstudy.add_observation(trial=trial,iteration=generation, objective=metric)\n",
        "\tstudy.finalize(trial=trial)\n",
        "\n",
        "print('\\n=====BEST RESULTS=====')\n",
        "results = study.get_best_result()\n",
        "for key in results: print('{:>10}: {}'.format(key, results[key]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Generation 1 - Population 1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}